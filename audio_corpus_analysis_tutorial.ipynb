{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_analysis_tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuomaseerola/audio/blob/master/audio_corpus_analysis_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTO_mMkGJCci"
      },
      "source": [
        "# Music and Science â€“ Audio Corpus Analysis Tutorial \n",
        "\n",
        "[Tuomas Eerola](https://www.durham.ac.uk/staff/tuomas-eerola/), Durham University, Music Department, 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Set up the libraries\n",
        "First activate few useful libraries (numpy, librosa, matplotlib) and then install `mirdata` library, that will take some time."
      ],
      "metadata": {
        "id": "tvPBl4QteUDC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3LSkxYNS5nY"
      },
      "source": [
        "#import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt \n",
        "%matplotlib inline\n",
        "print(librosa.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mirdata"
      ],
      "metadata": {
        "id": "S21mnM51cQBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2SD2rhaHDF9"
      },
      "source": [
        "# 2 Obtain a dataset\n",
        "\n",
        "Let's look at a classic genre categorization dataset by Tzanetakis & Cook (2002). The full data contains 100 audio excerpts from 10 genres, but we are going to start with a smaller set to keep this light and fast to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trn2ya5RNovU"
      },
      "source": [
        "import mirdata\n",
        "print(mirdata.list_datasets())\n",
        "gtzan_genre = mirdata.initialize('gtzan_genre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gtzan = mirdata.initialize('gtzan_genre', version='mini') # This is 100 excerpts\n",
        "#gtzan = mirdata.initialize('gtzan_genre')                  # This is 1000 excerpts\n",
        "gtzan.download()\n",
        "len(gtzan.track_ids)\n"
      ],
      "metadata": {
        "id": "-iOnROLScj6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at an example (number 88)."
      ],
      "metadata": {
        "id": "eIzIcKtlRmwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks = gtzan.load_tracks()\n",
        "#print(tracks.keys())\n",
        "ex = tracks[gtzan.track_ids[88]]\n",
        "print([\"Genre:\", ex.genre, \"Name:\", ex.track_id, \"Tempo:\",ex.tempo,])\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "librosa.display.waveshow(ex.audio[0],ex.audio[1])\n",
        "ipd.display(ipd.Audio(data=ex.audio[0], rate=ex.audio[1]))"
      ],
      "metadata": {
        "id": "awl0RzCgcmcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Extract features\n",
        "\n",
        "Let's extract some features and use them to predict genre."
      ],
      "metadata": {
        "id": "G2y2Sd86yV9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#import librosa\n",
        "#import librosa.display\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import natsort\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.DataFrame(columns = ['genre','bpm','rmse', 'spec_cent','spec_bw','rolloff','zcr','spec_ctr','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19','chroma1','chroma2','chroma3','chroma4','chroma5','chroma6','chroma7','chroma8','chroma9','chroma10','chroma11','chroma12']) \n",
        "for track in tracks:\n",
        "  print(track)\n",
        "  ex = tracks[track]\n",
        "  y, sr = librosa.load(ex.audio_path)\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "  rmse = librosa.feature.rms(y=y)\n",
        "  spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "  spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "  rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "  zcr = librosa.feature.zero_crossing_rate(y)\n",
        "  spec_ctr = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=512)\n",
        "  chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=512)\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "  df.loc[len(df)] = [ex.genre,ex.tempo,np.mean(rmse),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(spec_ctr),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),np.mean(chroma[0]),np.mean(chroma[1]),np.mean(chroma[2]),np.mean(chroma[3]),np.mean(chroma[4]),np.mean(chroma[5]),np.mean(chroma[6]),np.mean(chroma[7]),np.mean(chroma[8]),np.mean(chroma[9]),np.mean(chroma[10]),np.mean(chroma[11])]\n"
      ],
      "metadata": {
        "id": "IhTz8C53lbn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Explore features\n",
        "Let's look at the features."
      ],
      "metadata": {
        "id": "poY-vtyoeD_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('genre', axis=1).plot(kind='box', subplots=True,figsize=(15,15), layout=(6,7), sharex=False, sharey=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2acV4dukTKSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Build classifiers with the features\n",
        "\n",
        "We use"
      ],
      "metadata": {
        "id": "GiUVZ4u1MO-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)\n"
      ],
      "metadata": {
        "id": "SPT0u2o6CtGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "X = df.drop('genre', axis = 1)\n",
        "df['bpm'][np.isnan(df['bpm'])]=120\n",
        "\n",
        "X = preprocessing.normalize(X)\n",
        "y = df['genre']\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "test_size = 0.30 # taking 70:30 training and test set\n",
        "seed = 7  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
        "NN = KNeighborsClassifier()\n",
        "NN.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "IPOB7ge1MvsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Classify (start here!)"
      ],
      "metadata": {
        "id": "vQzQ99ecGKF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "Y3duMVBGTk79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X = df.drop('genre', axis = 1)\n",
        "Xn = preprocessing.normalize(X)\n",
        "y = df['genre']\n",
        "\n",
        "test_size = 0.30 # taking 70:30 training and test set\n",
        "seed = 9  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=test_size, random_state=seed)\n",
        "\n",
        "RF = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0).fit(X_train, y_train)\n",
        "RF.predict(X_test)\n",
        "print(round(RF.score(X_test, y_test), 4))\n",
        "y_pred_test = RF.predict(X_test)\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "rkei6FKVUenV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest correct classification is 0.65 (with the full data). Let's look at this model in model detail, which features are doing the most heavy lifting here.\n",
        "\n"
      ],
      "metadata": {
        "id": "pqWgDzrfemRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "importance = RF.feature_importances_\n",
        "n = df.columns[1:len(df.columns)]\n",
        "im = pd.DataFrame({'data': importance,'names': n})\n",
        "im2 = im.sort_values(by='data',ascending=False)\n",
        "print(im2.tail(5))\n",
        "# plot feature importance\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "#figure(figsize=(10, 5))\n",
        "plt.scatter(im2.names[0:9],im2.data[0:9],color='red')\n",
        "plt.plot(im2.names[0:9],im2.data[0:9])\n",
        "ax.set_title('10 strongest features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KM4VD5u-Wn3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the five best features and try building a simpler model?"
      ],
      "metadata": {
        "id": "6FwiTH3Gf-lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "X2 = df.filter(['rmse','spec_bw', 'mfcc3', 'bpm', 'spec_ctr'])\n",
        "\n",
        "test_size = 0.30 # taking 70:30 training and test set\n",
        "seed = 9  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=test_size, random_state=seed,stratify=y)\n",
        "\n",
        "RF = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0).fit(X_train, y_train)\n",
        "RF.predict(X_test)\n",
        "# Make predictions for the test set\n",
        "y_pred_test = RF.predict(X_test)\n",
        "print(round(RF.score(X_test, y_test), 4))\n",
        "\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test,labels=RF.classes_)\n",
        "print(conf_mat)\n"
      ],
      "metadata": {
        "id": "S2zRD25df9y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(y_test.array)\n",
        "print(np.unique(y_test))"
      ],
      "metadata": {
        "id": "maHr6FRqnWXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "cmp = ConfusionMatrixDisplay.from_estimator(RF,X_test,y_test,normalize='true')\n",
        "cmp.plot(ax=ax)\n"
      ],
      "metadata": {
        "id": "AP_OKzlCw-bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise confusion matrix"
      ],
      "metadata": {
        "id": "uX40hBG3j_Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Reshape\n",
        "matrix = confusion_matrix(y_test, y_pred_test)\n",
        "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Build the plot\n",
        "plt.figure(figsize=(16,7))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
        "            cmap=plt.cm.Blues, linewidths=0.2)\n",
        "\n",
        "# Add labels to the plot\n",
        "class_names = RF.classes_ #np.unique(y_test)\n",
        "tick_marks = np.arange(len(class_names))\n",
        "tick_marks2 = tick_marks + 0.5\n",
        "plt.xticks(tick_marks+0.5, class_names, rotation=90)\n",
        "plt.yticks(tick_marks2, class_names, rotation=0)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix for Random Forest Model')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TaBAEuj5j-dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "- Tzanetakis, G. & Cook, P. (2002). Musical genre classification of audio signals. _IEEE Transactions on Speech and Audio Processing, 10(5)_, 293-302 [doi:10.1109/TSA.2002.800560](https://ieeexplore.ieee.org/document/1021072)."
      ],
      "metadata": {
        "id": "ocFSenIwQiHW"
      }
    }
  ]
}